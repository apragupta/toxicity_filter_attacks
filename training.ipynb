{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4e2cff",
   "metadata": {},
   "source": [
    "# Following instructions from Gong et al to train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3271b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35db9d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T07:01:25.963364Z",
     "start_time": "2021-11-19T07:01:23.121456Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "import param as param\n",
    "from data_utils import data_helpers, tag_data_helpers\n",
    "from model.abuse_classifier import AbuseClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5892efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T07:01:28.075791Z",
     "start_time": "2021-11-19T07:01:26.601789Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded sent: (9232, 100)\n",
      "feature shape: (9232, 100)\n",
      "padded pos sentences: (9232, 100)\n",
      "debug padded_pos_sentences: ['&', 'O', 'V', 'D', 'N', 'N', ',', '&', 'O', 'V']\n",
      "pos feature shape: (9232, 100)\n",
      "load train data, input sent size: (9232, 100), input POS size: (9232, 100), label size: (9232, 2)\n",
      "split into train (7385 examples) and dev sets (1847 examples)\n"
     ]
    }
   ],
   "source": [
    "#load vocabulary and initial embeddings\n",
    "vocabulary, pos_vocabulary, init_embed = data_helpers.loadVocabEmb()\n",
    "\n",
    "pos_vocab_size = len(pos_vocabulary)\n",
    "vocab_size = len(vocabulary)\n",
    "\n",
    "x_train, length_train, attention_train, pos_train, pos_length_train, y_train, \\\n",
    "x_dev, length_dev, attention_dev, pos_dev, pos_length_dev, y_dev \\\n",
    "    = data_helpers.loadTrainData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a10f3a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T10:38:22.055996Z",
     "start_time": "2021-11-19T10:38:18.522993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Tensorflow version:  2.4.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train abusive language classifier\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "import os\n",
    "\n",
    "import param as param\n",
    "from data_utils import data_helpers\n",
    "from model.abuse_classifier import AbuseClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.app import flags\n",
    "\n",
    "tf.random.set_seed(111)\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Tensorflow version: \",tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ade9bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T10:38:22.071991Z",
     "start_time": "2021-11-19T10:38:22.058993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "flags.DEFINE_integer(\"embedding_dim\", 300, \"Dimensionality of character embedding (default: 128)\")\n",
    "flags.DEFINE_integer(\"pos_vocab_size\", 26, \"Vocab size of POS tags\")\n",
    "flags.DEFINE_integer(\"pos_embedding_dim\", 25, \"Dimensionality of pos tag embedding (default: 20)\")\n",
    "flags.DEFINE_float(\"dropout_keep_prob\", 0.99, \"Dropout keep probability (default: 0.5)\")\n",
    "flags.DEFINE_float(\"attention_lambda\", 0.2, \"Supervised attention lambda (default: 0.05)\")\n",
    "flags.DEFINE_string(\"attention_loss_type\", 'encoded', \"loss function of attention\")\n",
    "flags.DEFINE_float(\"l2_reg_lambda\", 0.02, \"L2 regularizaion lambda (default: 0.05)\")\n",
    "flags.DEFINE_integer(\"hidden_size\", 300, \"Dimensionality of RNN cell (default: 300)\")\n",
    "flags.DEFINE_integer(\"pos_hidden_size\", 25, \"Dimensionality of POS-RNN cell\")\n",
    "flags.DEFINE_integer(\"attention_size\", 20, \"Dimensionality of attention scheme (default: 50)\")\n",
    "flags.DEFINE_boolean(\"use_pos_flag\", True, \"use the sequence of POS tags\")\n",
    "# Training parameters -- evaluate_every should be 100\n",
    "flags.DEFINE_integer(\"batch_size\", 32, \"Batch Size (default: 32)\")\n",
    "flags.DEFINE_integer(\"num_epochs\", 60, \"Number of training epochs (default: 200)\")\n",
    "flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "flags.DEFINE_integer(\"checkpoint_every\", 500000, \"Save model after this many steps (default: 100)\")\n",
    "# flags.DEFINE_float(\"train_ratio\", 1.0, \"Ratio of training data\")\n",
    "# Misc Parameters\n",
    "flags.DEFINE_string(\"checkpoint\", '', \"model\")\n",
    "flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "#added so it works in command line \n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac14750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T08:17:19.516710Z",
     "start_time": "2021-11-19T08:17:18.867709Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b25f00a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-19T10:38:23.466541Z",
     "start_time": "2021-11-19T10:38:22.073991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded sent: (9232, 100)\n",
      "feature shape: (9232, 100)\n",
      "padded pos sentences: (9232, 100)\n",
      "debug padded_pos_sentences: ['&', 'O', 'V', 'D', 'N', 'N', ',', '&', 'O', 'V']\n",
      "pos feature shape: (9232, 100)\n",
      "load train data, input sent size: (9232, 100), input POS size: (9232, 100), label size: (9232, 2)\n",
      "split into train (7385 examples) and dev sets (1847 examples)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------  load data  -----------------------------\n",
    "vocabulary, pos_vocabulary, init_embed = data_helpers.loadVocabEmb()\n",
    "pos_vocab_size = len(pos_vocabulary)\n",
    "x_train, length_train, attention_train, pos_train, pos_length_train, y_train, \\\n",
    "x_dev, length_dev, attention_dev, pos_dev, pos_length_dev, y_dev \\\n",
    "    = data_helpers.loadTrainData()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19db47b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-11-19T10:38:18.526Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apra\\Desktop\\FALL 2021\\CY 7990\\toxicity_filter_attacks\\model\\abuse_classifier.py:48: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\apra\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\rnn.py:438: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\apra\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:981: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apra\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:903: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.LSTMCell` is deprecated and will be \"\n",
      "C:\\Users\\apra\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supervised attention with encoded loss.\n",
      "Writing to C:\\Users\\apra\\Desktop\\FALL 2021\\CY 7990\\model\n",
      "\n",
      "train a new model...\n",
      "[<tf.Variable 'embedding/W:0' shape=(18161, 300) dtype=float32>, <tf.Variable 'pos_embedding/W_pos:0' shape=(26, 26) dtype=float32>, <tf.Variable 'bi-rnn/bidirectional_rnn/fw/lstm_cell/kernel:0' shape=(626, 1200) dtype=float32>, <tf.Variable 'bi-rnn/bidirectional_rnn/fw/lstm_cell/bias:0' shape=(1200,) dtype=float32>, <tf.Variable 'bi-rnn/bidirectional_rnn/bw/lstm_cell/kernel:0' shape=(626, 1200) dtype=float32>, <tf.Variable 'bi-rnn/bidirectional_rnn/bw/lstm_cell/bias:0' shape=(1200,) dtype=float32>, <tf.Variable 'bi-rnn/Variable:0' shape=(600, 20) dtype=float32>, <tf.Variable 'bi-rnn/Variable_1:0' shape=(20,) dtype=float32>, <tf.Variable 'bi-rnn/Variable_2:0' shape=(20,) dtype=float32>, <tf.Variable 'fc-layer-1/W:0' shape=(600, 10) dtype=float32>, <tf.Variable 'fc-layer-1/b:0' shape=(10,) dtype=float32>, <tf.Variable 'fc-layer-2/W:0' shape=(10, 2) dtype=float32>, <tf.Variable 'fc-layer-2/b:0' shape=(2,) dtype=float32>, <tf.Variable 'cross_entropy/ration_W:0' shape=(100, 20) dtype=float32>, <tf.Variable 'cross_entropy/ration_b:0' shape=(20,) dtype=float32>, <tf.Variable 'cross_entropy/alpha_W:0' shape=(100, 20) dtype=float32>, <tf.Variable 'cross_entropy/alpha_b:0' shape=(20,) dtype=float32>]\n",
      "Num Steps:  13860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\apra\\Desktop\\FALL 2021\\CY 7990\\toxicity_filter_attacks\\data_utils\\data_helpers.py:115: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  data = np.array(data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 1.155071496963501 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.48955979917518383 dev pr_auc: 0.2666860881296538\n",
      "best pr auc: 0.2666860881296538\n",
      "Saved best model checkpoint.\n",
      "step 50, loss 0.8946983814239502 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.4981994501225271 dev pr_auc: 0.2797603716334595\n",
      "best pr auc: 0.2797603716334595\n",
      "Saved best model checkpoint.\n",
      "step 100, loss 0.711234986782074 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.4908941485864563 dev pr_auc: 0.2673578307531953\n",
      "step 150, loss 0.6377419233322144 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.48683656087502236 dev pr_auc: 0.2720135321499863\n",
      "step 200, loss 0.6310629844665527 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.4978214093598709 dev pr_auc: 0.26485074700124317\n",
      "step 250, loss 0.7347313165664673 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5031050146434761 dev pr_auc: 0.268896824157625\n",
      "step 300, loss 0.6292598843574524 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5367058155519694 dev pr_auc: 0.3001564613079616\n",
      "best pr auc: 0.3001564613079616\n",
      "Saved best model checkpoint.\n",
      "step 350, loss 0.46979957818984985 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5184702050086665 dev pr_auc: 0.28242718639130004\n",
      "step 400, loss 0.5492318868637085 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.48245547187854887 dev pr_auc: 0.25959989540795775\n",
      "step 450, loss 0.46912676095962524 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5220533739764509 dev pr_auc: 0.27868672417703955\n",
      "step 500, loss 0.5153586268424988 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5081704620166159 dev pr_auc: 0.2778344708086886\n",
      "step 550, loss 0.6706753373146057 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.53916980455442 dev pr_auc: 0.2920293019395166\n",
      "step 600, loss 0.5370093584060669 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5171298786683403 dev pr_auc: 0.28810237963830876\n",
      "step 650, loss 0.4710589349269867 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5536668459745383 dev pr_auc: 0.3011951641073771\n",
      "best pr auc: 0.3011951641073771\n",
      "Saved best model checkpoint.\n",
      "step 700, loss 0.4069386124610901 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5413581077042615 dev pr_auc: 0.30814746793495074\n",
      "best pr auc: 0.30814746793495074\n",
      "Saved best model checkpoint.\n",
      "step 750, loss 0.5447214841842651 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5989450720219951 dev pr_auc: 0.34584702704489967\n",
      "best pr auc: 0.34584702704489967\n",
      "Saved best model checkpoint.\n",
      "step 800, loss 0.4831072986125946 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5808050923435539 dev pr_auc: 0.3281647551646023\n",
      "step 850, loss 0.4397653043270111 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5526761699838623 dev pr_auc: 0.2934821777604143\n",
      "step 900, loss 0.4051460325717926 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5847618193772041 dev pr_auc: 0.32809262983173915\n",
      "step 950, loss 0.5285027623176575 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5524281274281274 dev pr_auc: 0.2992012297373417\n",
      "step 1000, loss 0.44227102398872375 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.6111417428725121 dev pr_auc: 0.3530824090566714\n",
      "best pr auc: 0.3530824090566714\n",
      "Saved best model checkpoint.\n",
      "step 1050, loss 0.39230677485466003 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5766944593867671 dev pr_auc: 0.3270864367092311\n",
      "step 1100, loss 0.37708085775375366 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5129124081047158 dev pr_auc: 0.29298107080510133\n",
      "step 1150, loss 0.5284004211425781 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5205240272547965 dev pr_auc: 0.2885765270933918\n",
      "step 1200, loss 0.48808375000953674 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5404458789074174 dev pr_auc: 0.301785786949273\n",
      "step 1250, loss 0.505527138710022 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5547994740302433 dev pr_auc: 0.31854782983329955\n",
      "step 1300, loss 0.42162638902664185 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5538386826848365 dev pr_auc: 0.3188767799724021\n",
      "step 1350, loss 0.33276253938674927 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5919826967903891 dev pr_auc: 0.34611724851145315\n",
      "step 1400, loss 0.4213145971298218 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5987284083437929 dev pr_auc: 0.3534871716656091\n",
      "best pr auc: 0.3534871716656091\n",
      "Saved best model checkpoint.\n",
      "step 1450, loss 0.30326080322265625 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5539216125754587 dev pr_auc: 0.3216165127602908\n",
      "step 1500, loss 0.5412738919258118 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5591977466977467 dev pr_auc: 0.31945084365982124\n",
      "step 1550, loss 0.3678137958049774 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5483877233877235 dev pr_auc: 0.31171129740265546\n",
      "step 1600, loss 0.38342687487602234 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5435479050863666 dev pr_auc: 0.31217692162224564\n",
      "step 1650, loss 0.4627009332180023 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5552910764449226 dev pr_auc: 0.3094042325680907\n",
      "step 1700, loss 0.26875439286231995 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5516406670252825 dev pr_auc: 0.3057271198639014\n",
      "step 1750, loss 0.4530148208141327 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5848746339130955 dev pr_auc: 0.33776434075652695\n",
      "step 1800, loss 0.36957839131355286 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5727422150499074 dev pr_auc: 0.31741010227929556\n",
      "step 1850, loss 0.4071774184703827 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5764165321857629 dev pr_auc: 0.33214987702593335\n",
      "step 1900, loss 0.49889689683914185 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5962830972446357 dev pr_auc: 0.34097670629991284\n",
      "step 1950, loss 0.4274584650993347 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5748057498057498 dev pr_auc: 0.33094803387686755\n",
      "step 2000, loss 0.38798636198043823 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5854147988763373 dev pr_auc: 0.33177823120602534\n",
      "step 2050, loss 0.33656078577041626 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5718068256529795 dev pr_auc: 0.3301278100754977\n",
      "step 2100, loss 0.2921801507472992 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.6020448568525492 dev pr_auc: 0.34367464786593177\n",
      "step 2150, loss 0.5544049739837646 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.6124200585739047 dev pr_auc: 0.3527767473617224\n",
      "step 2200, loss 0.4121799170970917 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5541278166278166 dev pr_auc: 0.3119536912232327\n",
      "step 2250, loss 0.34900471568107605 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5618836291913215 dev pr_auc: 0.3283512264655848\n",
      "step 2300, loss 0.5338619947433472 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.55729633614249 dev pr_auc: 0.31426266715265216\n",
      "step 2350, loss 0.409529447555542 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5621391429083736 dev pr_auc: 0.3104736905863851\n",
      "step 2400, loss 0.2937602996826172 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5780176020560637 dev pr_auc: 0.3276142351327494\n",
      "step 2450, loss 0.3837697505950928 \n",
      "\n",
      " Evaluation:\n",
      "dev roc_auc: 0.5754930966469429 dev pr_auc: 0.32486439881058415\n",
      "step 2500, loss 0.27384236454963684 \n"
     ]
    }
   ],
   "source": [
    "# -------------------------- model training --------------------------\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    #initialization code required to make tensorflow work on my systemabs\n",
    "\n",
    "    config = tf.compat.v1.ConfigProto(\n",
    "            allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "            log_device_placement=FLAGS.log_device_placement)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    \n",
    "    \n",
    "    sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "    with sess.as_default():\n",
    "        model = AbuseClassifier(\n",
    "            max_sequence_length=param.max_sent_len,\n",
    "            num_classes=2,\n",
    "            pos_vocab_size=pos_vocab_size,\n",
    "            init_embed=init_embed,\n",
    "            hidden_size=FLAGS.hidden_size,\n",
    "            attention_size=FLAGS.attention_size,\n",
    "            keep_prob=FLAGS.dropout_keep_prob,\n",
    "            attention_lambda=FLAGS.attention_lambda,\n",
    "            attention_loss_type=FLAGS.attention_loss_type,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda,\n",
    "            use_pos_flag=FLAGS.use_pos_flag)\n",
    "\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.compat.v1.train.AdamOptimizer()\n",
    "        grads_and_vars = optimizer.compute_gradients(model.loss, aggregation_method=2)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "        # save models\n",
    "        if FLAGS.checkpoint == \"\":\n",
    "            out_dir = os.path.abspath(os.path.join(os.path.pardir, \"model\"))\n",
    "            print(\"Writing to {}\\n\".format(out_dir))\n",
    "        else:\n",
    "            out_dir = FLAGS.checkpoint\n",
    "        if (FLAGS.attention_lambda == 0.0):\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"model_noatt_checkpoints\"))\n",
    "        else:\n",
    "            checkpoint_dir = os.path.abspath(\n",
    "                os.path.join(out_dir, \"model_att=\" + FLAGS.attention_loss_type + \"_checkpoints\"))\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver =  tf.compat.v1.train.Saver(tf.compat.v1.global_variables())\n",
    "        # initalize variables\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        # resotre models\n",
    "        # try:\n",
    "        #    saver.restore(sess, os.path.join(checkpoint_dir, \"best_model\"))\n",
    "        #    print(\"restoring from trained model...\")\n",
    "        # except:\n",
    "        print(\"train a new model...\")\n",
    "        print(tf.compat.v1.trainable_variables())\n",
    "\n",
    "\n",
    "        def train_step(x_batch, pos_batch, y_batch, sequence_length, pos_sequence_length, attention_batch):\n",
    "            feed_dict = {\n",
    "                model.input_word: x_batch,\n",
    "                model.input_pos: pos_batch,\n",
    "                model.input_y: y_batch,\n",
    "                model.sequence_length: sequence_length,\n",
    "                model.input_attention: attention_batch,\n",
    "                model.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "            }\n",
    "            _, step, loss = sess.run(\n",
    "                [train_op, global_step, model.loss],\n",
    "                feed_dict)\n",
    "            if (step % FLAGS.evaluate_every == 0):\n",
    "                print(\"step {}, loss {:} \".format(step, loss))\n",
    "\n",
    "\n",
    "        def dev_step(x_dev, pos_dev, y_dev, length_dev, pos_length_dev, writer=None):\n",
    "            dev_scores = []\n",
    "            # loss_list = []\n",
    "            pos = 0\n",
    "            gap = 50\n",
    "            while (pos < len(x_dev)):\n",
    "                x_batch = x_dev[pos:pos + gap]\n",
    "                pos_batch = pos_dev[pos:pos + gap]\n",
    "                y_batch = y_dev[pos:pos + gap]\n",
    "                sequence_length = length_dev[pos:pos + gap]\n",
    "                pos_sequence_length = pos_length_dev[pos:pos + gap]\n",
    "                pos += gap\n",
    "                feed_dict = {\n",
    "                    model.input_word: x_batch,\n",
    "                    model.input_pos: pos_batch,\n",
    "                    model.input_y: y_batch,\n",
    "                    model.sequence_length: sequence_length,\n",
    "                    model.dropout_keep_prob: 0.99999\n",
    "                }\n",
    "                # step, loss, scores = sess.run(\n",
    "                #    [global_step, model.loss, model.prob],\n",
    "                #    feed_dict)\n",
    "                step, scores = sess.run(\n",
    "                    [global_step, model.prob],\n",
    "                    feed_dict)\n",
    "                dev_scores = dev_scores + list([s[0] for s in scores])\n",
    "                # loss_list.append(loss)\n",
    "            gold_scores = [t[0] for t in y_dev]\n",
    "            pred_scores = dev_scores[:]\n",
    "            fpr, tpr, _ = roc_curve(gold_scores, pred_scores, pos_label=1)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            prec, recall, _ = precision_recall_curve(gold_scores, pred_scores, pos_label=1)\n",
    "            pr_auc = auc(recall, prec)\n",
    "            # avg_loss = np.mean(loss_list)\n",
    "            print(\"dev roc_auc:\", roc_auc, \"dev pr_auc:\", pr_auc)\n",
    "            return roc_auc, pr_auc  # , avg_loss\n",
    "\n",
    "\n",
    "        # Generate batches\n",
    "        batches = data_helpers.batch_iter(\n",
    "            list(zip(x_train, y_train, pos_train, length_train, pos_length_train, attention_train)), FLAGS.batch_size,\n",
    "            FLAGS.num_epochs)\n",
    "        best_auc = 0.10\n",
    "\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch, pos_batch, length_batch, pos_length_batch, attention_batch = zip(*batch)\n",
    "            train_step(x_batch, pos_batch, y_batch, length_batch, pos_length_batch, attention_batch)\n",
    "            current_step = tf.compat.v1.train.global_step(sess, global_step)\n",
    "            if (current_step % FLAGS.evaluate_every == 0):\n",
    "                print(\"\\n Evaluation:\")\n",
    "                roc_auc, pr_auc = dev_step(x_dev, pos_dev, y_dev, length_dev, pos_length_dev)\n",
    "                # model selection criteria: roc_auc\n",
    "                # if (best_auc < roc_auc):\n",
    "                #    best_auc = roc_auc\n",
    "                if (best_auc < pr_auc):\n",
    "                    best_auc = pr_auc\n",
    "                    print(\"best pr auc:\", best_auc)\n",
    "                    checkpoint_prefix = os.path.join(checkpoint_dir, \"best_model\")\n",
    "                    path = saver.save(sess, checkpoint_prefix)\n",
    "                    print(\"Saved best model checkpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a303021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
