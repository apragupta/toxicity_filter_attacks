{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f4a350a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T07:09:07.158000Z",
     "start_time": "2021-12-06T07:09:07.153999Z"
    }
   },
   "source": [
    "# This attack simply inserts high-confidence 'positive' words based on queries from the test set to the model on sentences around that are negative. \n",
    "\n",
    "- This is a black box attack, assumes only access to confidence predictions and some preexising dataset of sentences, which may be benign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b62a6",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "1. Load all test sentences\n",
    "2. Score them individually\n",
    "3. Get top N (10?) benign, with high-confidence \n",
    "4. Generate attack tests (vary combinations of (`a=0,1,2` and `b=0,1,2`):\n",
    " - Adding `a` sentences before and `b` sentences after, chosen randomly from step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a66eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T09:20:07.274883Z",
     "start_time": "2021-12-06T09:20:07.258884Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-d854e22f2352>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mexperiments\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mparams\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdata_utils_v2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_helpers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mloadVocabEmb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabuse_classifier\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mAbuseClassifier\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os \n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from experiments import params\n",
    "from data_utils_v2.data_helpers import loadVocabEmb\n",
    "from model.abuse_classifier import AbuseClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82e0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 300, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_integer(\"pos_vocab_size\", 26, \"Vocab size of POS tags\")\n",
    "tf.flags.DEFINE_integer(\"pos_embedding_dim\", 25, \"Dimensionality of pos tag embedding (default: 20)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 1.0, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"attention_lambda\", 0, \"Supervised attention lambda (default: 0.05)\")\n",
    "tf.flags.DEFINE_string(\"attention_loss_type\", 'encoded', \"loss function of attention\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.02, \"L2 regularization lambda (default: 0.05)\")\n",
    "tf.flags.DEFINE_integer(\"hidden_size\", 300, \"Dimensionality of RNN cell (default: 300)\")\n",
    "tf.flags.DEFINE_integer(\"pos_hidden_size\", 25, \"Dimensionality of POS-RNN cell\")\n",
    "tf.flags.DEFINE_integer(\"attention_size\", 20, \"Dimensionality of attention scheme (default: 50)\")\n",
    "tf.flags.DEFINE_boolean(\"use_pos_flag\", True, \"use the sequence of POS tags\")\n",
    "# Training parameters -- evaluate_every should be 100\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 32, \"Batch Size (default: 32)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 60, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 50, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 500000, \"Save model after this many steps (default: 100)\")\n",
    "# tf.flags.DEFINE_float(\"train_ratio\", 1.0, \"Ratio of training data\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_string(\"checkpoint\", '', \"model\")\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1bf2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:03:09.413747Z",
     "start_time": "2021-12-06T12:03:09.404748Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model_save_folder_name = (sys.argv[1] if len(sys.argv) > 1 else False) or \"model_noatt_checkpoints\"\n",
    "print(f\"Running model from {model_save_folder_name}\")\n",
    "model_folder_path = '../model'\n",
    "checkpoint_dir = os.path.abspath(os.path.join(model_folder_path, model_save_folder_name))\n",
    "model_path = os.path.join(checkpoint_dir, \"best_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7f173",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../preprocessing/dump/'\n",
    "dump_folder = \"../preprocessing/dump/\"\n",
    "print(f\"Using data from {data_path} and dump from {dump_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vocab(dump_folder):\n",
    "    vocabulary, pos_vocabulary, init_embed = loadVocabEmb(dump_folder)\n",
    "    return vocabulary, pos_vocabulary, init_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d6f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287e28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model_path, data_path, dump_folder):\n",
    "    vocabulary, pos_vocabulary, init_embed = load_vocab(dump_folder)\n",
    "    x_test, length_test, _, pos_test, pos_length_test, y_test = loadData(\n",
    "        dump_folder,  # dump_folder\n",
    "        data_path,  # data_path\n",
    "        \"test\",  # data_type\n",
    "        type=\"sentence\"\n",
    "    )\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto(\n",
    "            allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "            log_device_placement=FLAGS.log_device_placement\n",
    "        )\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            model = AbuseClassifier(\n",
    "                max_sequence_length=params.max_sent_len,\n",
    "                num_classes=2,\n",
    "                pos_vocab_size=FLAGS.pos_vocab_size,\n",
    "                init_embed=init_embed,\n",
    "                hidden_size=FLAGS.hidden_size,\n",
    "                attention_size=FLAGS.attention_size,\n",
    "                keep_prob=FLAGS.dropout_keep_prob,\n",
    "                attention_lambda=FLAGS.attention_lambda,\n",
    "                attention_loss_type=FLAGS.attention_loss_type,\n",
    "                l2_reg_lambda=0.1,\n",
    "                use_pos_flag=FLAGS.use_pos_flag)\n",
    "\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            saver = tf.train.Saver(tf.all_variables())\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            saver.restore(sess, model_path)\n",
    "\n",
    "            dev_scores = []\n",
    "            pos = 0\n",
    "            gap = 50\n",
    "            while pos < len(x_test):\n",
    "                x_batch = x_test[pos:pos + gap]\n",
    "                pos_batch = pos_test[pos:pos + gap]\n",
    "                y_batch = y_test[pos:pos + gap]\n",
    "                length_batch = length_test[pos:pos + gap]\n",
    "                pos_length_batch = pos_length_test[pos:pos + gap]\n",
    "                pos += gap\n",
    "                # score sentences\n",
    "                feed_dict = {\n",
    "                    model.input_word: x_batch,\n",
    "                    model.input_pos: pos_batch,\n",
    "                    model.input_y: y_batch,\n",
    "                    model.sequence_length: length_batch,\n",
    "                    model.dropout_keep_prob: 1.0\n",
    "                }\n",
    "                step, scores = sess.run([global_step, model.prob], feed_dict)\n",
    "                dev_scores = dev_scores + list([s[0] for s in scores])\n",
    "    return dev_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c61792",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(model_path, data_path, dump_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f9108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55c6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d4852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7e1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d27bad05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:42:04.952226Z",
     "start_time": "2021-12-06T10:42:04.884226Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(path_to_training, \"rb\") as handle:\n",
    "    sent_list, label_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8186da96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:42:06.787097Z",
     "start_time": "2021-12-06T10:42:06.772099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nice', 'try'] 0\n",
      "[\"i'm\", 'a', 'conservative', 'libertarian'] 0\n",
      "['but', 'i', 'can', 'spot', 'a', 'racist', 'from', 'a', 'mile', 'away'] 0\n",
      "['because', 'they', 'make', 'comments', 'like', 'that'] 0\n",
      "['stupid', ',', 'senseless', ',', 'idiotic', ',', 'mind', 'numbing', ',', 'low', 'i', 'q', 'comments'] 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(sent_list[i],label_list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d55eb1dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:36:58.473844Z",
     "start_time": "2021-12-06T10:36:58.468838Z"
    }
   },
   "outputs": [],
   "source": [
    "#create a dataframe using sentence and labels\n",
    "\n",
    "test_df = pd.DataFrame(columns=[\"sentence\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5bc490b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:36:58.952836Z",
     "start_time": "2021-12-06T10:36:58.906838Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df[\"sentence\"] = sent_list\n",
    "test_df[\"label\"] = [l[0] for l in label_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05f17d17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:36:59.380837Z",
     "start_time": "2021-12-06T10:36:59.367837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nice, try]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i'm, a, conservative, libertarian]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[but, i, can, spot, a, racist, from, a, mile, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[because, they, make, comments, like, that]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[stupid, ,, senseless, ,, idiotic, ,, mind, nu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>[it, 's, not, them, dying, if, they, vote, for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5013</th>\n",
       "      <td>[they, got, all, of, the, privileges, with, no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>[omg, that, bitch, is, going, to, have, a, hea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>[that, was, the, most, well, spoken, video, u,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>[hahaha]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5017 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "0                                           [nice, try]      0\n",
       "1                   [i'm, a, conservative, libertarian]      0\n",
       "2     [but, i, can, spot, a, racist, from, a, mile, ...      0\n",
       "3           [because, they, make, comments, like, that]      0\n",
       "4     [stupid, ,, senseless, ,, idiotic, ,, mind, nu...      1\n",
       "...                                                 ...    ...\n",
       "5012  [it, 's, not, them, dying, if, they, vote, for...      0\n",
       "5013  [they, got, all, of, the, privileges, with, no...      1\n",
       "5014  [omg, that, bitch, is, going, to, have, a, hea...      1\n",
       "5015  [that, was, the, most, well, spoken, video, u,...      0\n",
       "5016                                           [hahaha]      0\n",
       "\n",
       "[5017 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a0c42c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:36:59.886941Z",
     "start_time": "2021-12-06T10:36:59.876943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.827387\n",
       "1    0.172613\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()/len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f508051",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:12.099359Z",
     "start_time": "2021-12-06T12:05:12.052362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment #</th>\n",
       "      <th>Assigned to:</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prosocial</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>@user06652 You can't be serious?</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Just google \"United Nations\".</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>You may learn something.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Feminist = Misandrist</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Where the fuck do these fat cunts learn this s...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26367</th>\n",
       "      <td>13038</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>I will donate and I would encourage others to ...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26368</th>\n",
       "      <td>13038</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>Do anything it takes to destroy these stupid c...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26369</th>\n",
       "      <td>13039</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>\"100 lkies\". Try 6k :D</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26370</th>\n",
       "      <td>13040</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>You bet your faggot ass im sending you money r...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26371</th>\n",
       "      <td>13041</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>add me on steam and get cs go lol you would lo...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Comment # Assigned to:  \\\n",
       "0             1       Lauren   \n",
       "1             1       Lauren   \n",
       "2             1       Lauren   \n",
       "3             2       Lauren   \n",
       "4             3       Lauren   \n",
       "...         ...          ...   \n",
       "26367     13038        Tiana   \n",
       "26368     13038        Tiana   \n",
       "26369     13039        Tiana   \n",
       "26370     13040        Tiana   \n",
       "26371     13041        Tiana   \n",
       "\n",
       "                                                Sentence Prosocial Abusive  \n",
       "0                       @user06652 You can't be serious?        No      No  \n",
       "1                          Just google \"United Nations\".        No      No  \n",
       "2                               You may learn something.        No      No  \n",
       "3                                  Feminist = Misandrist        No     Yes  \n",
       "4      Where the fuck do these fat cunts learn this s...        No     Yes  \n",
       "...                                                  ...       ...     ...  \n",
       "26367  I will donate and I would encourage others to ...        No      No  \n",
       "26368  Do anything it takes to destroy these stupid c...        No     Yes  \n",
       "26369                             \"100 lkies\". Try 6k :D        No      No  \n",
       "26370  You bet your faggot ass im sending you money r...        No     Yes  \n",
       "26371  add me on steam and get cs go lol you would lo...        No      No  \n",
       "\n",
       "[26372 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data we will be attacking\n",
    "target = pd.read_csv(target_path)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0330bb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nice, try]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[i'm, a, conservative, libertarian]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[but, i, can, spot, a, racist, from, a, mile, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[because, they, make, comments, like, that]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[designed, to, not, only, insult, one, person,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5009</th>\n",
       "      <td>[$mention$, i, 've, caught, crabs, twice, ,, b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5010</th>\n",
       "      <td>[try, saying, that, with, your, mouth, full]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>[it, 's, not, them, dying, if, they, vote, for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5015</th>\n",
       "      <td>[that, was, the, most, well, spoken, video, u,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5016</th>\n",
       "      <td>[hahaha]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4151 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label\n",
       "0                                           [nice, try]      0\n",
       "1                   [i'm, a, conservative, libertarian]      0\n",
       "2     [but, i, can, spot, a, racist, from, a, mile, ...      0\n",
       "3           [because, they, make, comments, like, that]      0\n",
       "5     [designed, to, not, only, insult, one, person,...      0\n",
       "...                                                 ...    ...\n",
       "5009  [$mention$, i, 've, caught, crabs, twice, ,, b...      0\n",
       "5010       [try, saying, that, with, your, mouth, full]      0\n",
       "5012  [it, 's, not, them, dying, if, they, vote, for...      0\n",
       "5015  [that, was, the, most, well, spoken, video, u,...      0\n",
       "5016                                           [hahaha]      0\n",
       "\n",
       "[4151 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_sentences = test_df[test_df['label']==0]\n",
    "pos_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddb9100e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:37:02.991558Z",
     "start_time": "2021-12-06T10:37:02.972571Z"
    }
   },
   "outputs": [],
   "source": [
    "only_positive_test_sentences = []\n",
    "for i, sentence in enumerate(pos_sentences[\"sentence\"]):\n",
    "    only_positive_test_sentences.append((\n",
    "        i,\n",
    "        \"N/A\",\n",
    "        \" \".join(sentence),\n",
    "        \"No\",\n",
    "        \"No\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2626a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment #</th>\n",
       "      <th>Assigned to:</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prosocial</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>nice try</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>i'm a conservative libertarian</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>but i can spot a racist from a mile away</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>N/A</td>\n",
       "      <td>because they make comments like that</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>N/A</td>\n",
       "      <td>designed to not only insult one person , but a...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>4146</td>\n",
       "      <td>N/A</td>\n",
       "      <td>$mention$ i 've caught crabs twice , but i'm a...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4147</th>\n",
       "      <td>4147</td>\n",
       "      <td>N/A</td>\n",
       "      <td>try saying that with your mouth full</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4148</th>\n",
       "      <td>4148</td>\n",
       "      <td>N/A</td>\n",
       "      <td>it 's not them dying if they vote for a warmonger</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>4149</td>\n",
       "      <td>N/A</td>\n",
       "      <td>that was the most well spoken video u have don...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4150</th>\n",
       "      <td>4150</td>\n",
       "      <td>N/A</td>\n",
       "      <td>hahaha</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4151 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Comment # Assigned to:  \\\n",
       "0             0          N/A   \n",
       "1             1          N/A   \n",
       "2             2          N/A   \n",
       "3             3          N/A   \n",
       "4             4          N/A   \n",
       "...         ...          ...   \n",
       "4146       4146          N/A   \n",
       "4147       4147          N/A   \n",
       "4148       4148          N/A   \n",
       "4149       4149          N/A   \n",
       "4150       4150          N/A   \n",
       "\n",
       "                                               Sentence Prosocial Abusive  \n",
       "0                                              nice try        No      No  \n",
       "1                        i'm a conservative libertarian        No      No  \n",
       "2              but i can spot a racist from a mile away        No      No  \n",
       "3                  because they make comments like that        No      No  \n",
       "4     designed to not only insult one person , but a...        No      No  \n",
       "...                                                 ...       ...     ...  \n",
       "4146  $mention$ i 've caught crabs twice , but i'm a...        No      No  \n",
       "4147               try saying that with your mouth full        No      No  \n",
       "4148  it 's not them dying if they vote for a warmonger        No      No  \n",
       "4149  that was the most well spoken video u have don...        No      No  \n",
       "4150                                             hahaha        No      No  \n",
       "\n",
       "[4151 rows x 5 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_positive_test_sentences_df = pd.DataFrame(only_positive_test_sentences, columns = target.columns.copy())\n",
    "only_positive_test_sentences_df.to_csv(\"only_positive_test_sentences.csv\", index=False)\n",
    "only_positive_test_sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4360f69c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:12.810187Z",
     "start_time": "2021-12-06T12:05:12.798189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment #</th>\n",
       "      <th>Assigned to:</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prosocial</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Feminist = Misandrist</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Where the fuck do these fat cunts learn this s...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>I feel sorry for the birds being around such a...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Wow, I actually thought she was decent looking...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Dat's one dumb cunt.ï»¿</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26356</th>\n",
       "      <td>13031</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>Illegal immigrants do need to get the fuck out...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26357</th>\n",
       "      <td>13032</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>@user11016 bec he's a retard who profits of th...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26364</th>\n",
       "      <td>13037</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>wait woah I'm no fag but I love your vids</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26368</th>\n",
       "      <td>13038</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>Do anything it takes to destroy these stupid c...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26370</th>\n",
       "      <td>13040</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>You bet your faggot ass im sending you money r...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4424 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Comment # Assigned to:  \\\n",
       "3             2       Lauren   \n",
       "4             3       Lauren   \n",
       "13            8       Lauren   \n",
       "14            9       Lauren   \n",
       "15            9       Lauren   \n",
       "...         ...          ...   \n",
       "26356     13031        Tiana   \n",
       "26357     13032        Tiana   \n",
       "26364     13037        Tiana   \n",
       "26368     13038        Tiana   \n",
       "26370     13040        Tiana   \n",
       "\n",
       "                                                Sentence Prosocial Abusive  \n",
       "3                                  Feminist = Misandrist        No     Yes  \n",
       "4      Where the fuck do these fat cunts learn this s...        No     Yes  \n",
       "13     I feel sorry for the birds being around such a...        No     Yes  \n",
       "14     Wow, I actually thought she was decent looking...        No     Yes  \n",
       "15                               Dat's one dumb cunt.ï»¿        No     Yes  \n",
       "...                                                  ...       ...     ...  \n",
       "26356  Illegal immigrants do need to get the fuck out...        No     Yes  \n",
       "26357  @user11016 bec he's a retard who profits of th...        No     Yes  \n",
       "26364          wait woah I'm no fag but I love your vids        No     Yes  \n",
       "26368  Do anything it takes to destroy these stupid c...        No     Yes  \n",
       "26370  You bet your faggot ass im sending you money r...        No     Yes  \n",
       "\n",
       "[4424 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_toxic_sentences = target[target[\"Abusive\"] == 'Yes']\n",
    "target_toxic_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ea15d523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:14.320456Z",
     "start_time": "2021-12-06T12:05:14.300443Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "def attack_row(row):\n",
    "    \"\"\"\n",
    "    Attacks a single row of the dataframe to evade the toxicity detector by adding a fixed % of words by length at the beginning and\n",
    "    end of the sentence. Returns the modified sentence\n",
    "    \"\"\"\n",
    "    PERC_INS = 0.5 \n",
    "   \n",
    "    sentence = row[\"Sentence\"]\n",
    "\n",
    "    \n",
    "    #only attack abusive points\n",
    "    if row[\"Abusive\"]==\"Yes\":\n",
    "        len_sent = len(sentence.split(\" \"))\n",
    "        \n",
    "        NUM_INS = min(len(attack_words),math.ceil(PERC_INS*len_sent))\n",
    "        insert_first = random.sample(attack_words, NUM_INS)\n",
    "        insert_last = random.sample(attack_words, NUM_INS)\n",
    "        \n",
    "        return \" \".join(insert_first) + \" \" + sentence + \" \" + \" \".join(insert_last)\n",
    "    else:\n",
    "        return sentence\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c78b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "093016a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:16.485529Z",
     "start_time": "2021-12-06T12:05:16.468517Z"
    }
   },
   "outputs": [],
   "source": [
    "attacked_target = target\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "5662f37d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:17.648450Z",
     "start_time": "2021-12-06T12:05:17.213453Z"
    }
   },
   "outputs": [],
   "source": [
    "attacked_target[\"Sentence\"] = target.apply(attack_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "d5e5b4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:23.414495Z",
     "start_time": "2021-12-06T12:05:23.396483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment #</th>\n",
       "      <th>Assigned to:</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Prosocial</th>\n",
       "      <th>Abusive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>@user06652 You can't be serious?</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>Just google \"United Nations\".</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>You may learn something.</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>credit growing Feminist = Misandrist communist...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Lauren</td>\n",
       "      <td>benefit familiar private communists activism W...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26367</th>\n",
       "      <td>13038</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>I will donate and I would encourage others to ...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26368</th>\n",
       "      <td>13038</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>belief field shall sources tend Do anything it...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26369</th>\n",
       "      <td>13039</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>\"100 lkies\". Try 6k :D</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26370</th>\n",
       "      <td>13040</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>janice throughout accusing wise list forgotten...</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26371</th>\n",
       "      <td>13041</td>\n",
       "      <td>Tiana</td>\n",
       "      <td>add me on steam and get cs go lol you would lo...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26372 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Comment # Assigned to:  \\\n",
       "0             1       Lauren   \n",
       "1             1       Lauren   \n",
       "2             1       Lauren   \n",
       "3             2       Lauren   \n",
       "4             3       Lauren   \n",
       "...         ...          ...   \n",
       "26367     13038        Tiana   \n",
       "26368     13038        Tiana   \n",
       "26369     13039        Tiana   \n",
       "26370     13040        Tiana   \n",
       "26371     13041        Tiana   \n",
       "\n",
       "                                                Sentence Prosocial Abusive  \n",
       "0                       @user06652 You can't be serious?        No      No  \n",
       "1                          Just google \"United Nations\".        No      No  \n",
       "2                               You may learn something.        No      No  \n",
       "3      credit growing Feminist = Misandrist communist...        No     Yes  \n",
       "4      benefit familiar private communists activism W...        No     Yes  \n",
       "...                                                  ...       ...     ...  \n",
       "26367  I will donate and I would encourage others to ...        No      No  \n",
       "26368  belief field shall sources tend Do anything it...        No     Yes  \n",
       "26369                             \"100 lkies\". Try 6k :D        No      No  \n",
       "26370  janice throughout accusing wise list forgotten...        No     Yes  \n",
       "26371  add me on steam and get cs go lol you would lo...        No      No  \n",
       "\n",
       "[26372 rows x 5 columns]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacked_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "31e5335a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:39.582861Z",
     "start_time": "2021-12-06T12:05:39.476863Z"
    }
   },
   "outputs": [],
   "source": [
    "#save the attacked data to test!\n",
    "\n",
    "attacked_target.to_csv(adv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "51033fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T12:05:40.232862Z",
     "start_time": "2021-12-06T12:05:40.228860Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'benefit familiar private communists activism Where the fuck do these fat cunts learn this shit?ï»¿ student posting wives games de'"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacked_target.iloc[4][\"Sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "129cea25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-06T10:44:12.175248Z",
     "start_time": "2021-12-06T10:44:12.156248Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../experiments/data/exp_3/adv\\\\test_comments.csv'"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bc9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}